{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be6fdc7-53aa-4617-aa4e-6985caf5ef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated layer sizes: 32 -> 16 -> 8 -> 4 -> 2\n",
      "Figure saved as generated_patches_6.png\n"
     ]
    }
   ],
   "source": [
    "from testing import PSGANInference\n",
    "from psgan import PSGAN\n",
    "from models.target import YOLOv8TargetModel\n",
    "# Configuration\n",
    "IMG_SIZE = 256\n",
    "PATCH_SIZE = 32\n",
    "CHECKPOINT_DIR = './checkpoints_distributed/'\n",
    "MAX_EPOCHS = 100\n",
    "\n",
    "# Roboflow dataset configuration\n",
    "DATASET_CONFIG = {\n",
    "    'api_key': \"Yp0GigDoIjDjIoTrGiyA\",\n",
    "    'workspace': \"mrsyaban\",\n",
    "    'project': \"traffic-signs-id\",\n",
    "    'version': 2\n",
    "}\n",
    "\n",
    "# YOLO model path\n",
    "YOLO_MODEL_PATH = './pretrained_models/yolov8x-best.pt'\n",
    "\n",
    "# Initialize YOLO model\n",
    "print(\"Loading YOLO model...\")\n",
    "yolo_model = YOLOv8TargetModel(\n",
    "    model_path=YOLO_MODEL_PATH,\n",
    "    confidence_threshold=0.1\n",
    ")\n",
    "\n",
    "# Initialize inference model\n",
    "print(\"Initializing PSGAN inference...\")\n",
    "psgan_inference = PSGANInference(\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    image_size=IMG_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate across epochs\n",
    "print(\"Starting multi-epoch evaluation...\")\n",
    "results = psgan_inference.test_against_yolo_epochs(\n",
    "    dataset_path=None,  # Will be auto-downloaded\n",
    "    dataset_config=DATASET_CONFIG,\n",
    "    yolo_model=yolo_model,\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    max_batches=200,  # Limit for faster evaluation\n",
    "    save_results=True\n",
    ")\n",
    "\n",
    "# Visualize results\n",
    "if results:\n",
    "    print(\"Creating mAP decline visualization...\")\n",
    "    psgan_inference.visualize_map_decline(\n",
    "        results=results,\n",
    "        save_path='map_decline_across_epochs.png',\n",
    "        title='mAP Decline Across PS-GAN Training Epochs'\n",
    "    )\n",
    "\n",
    "    # Visualize adversarial samples from latest epoch\n",
    "    print(\"Creating adversarial samples visualization...\")\n",
    "    psgan_inference.visualize_latest_adversarial_samples(\n",
    "        yolo_model=yolo_model,\n",
    "        num_samples=6,\n",
    "        save_path='latest_epoch_adversarial_samples.png'\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n=== Evaluation Summary ===\")\n",
    "    print(f\"Dataset: {results['dataset_info']['num_classes']} classes, {results['dataset_info']['num_images']} images\")\n",
    "    print(f\"Classes: {results['dataset_info']['classes']}\")\n",
    "    print(f\"Baseline mAP: {results['baseline_map']:.4f}\")\n",
    "    print(f\"Seed patch mAP: {results['seed_patch_map']:.4f}\")\n",
    "    print(f\"Seed patch reduction: {results['baseline_map'] - results['seed_patch_map']:.4f} ({((results['baseline_map'] - results['seed_patch_map'])/results['baseline_map'])*100:.1f}%)\")\n",
    "\n",
    "    if results['map_scores']:\n",
    "        final_map = results['map_scores'][-1]\n",
    "        min_map = min(results['map_scores'])\n",
    "        print(f\"Final mAP (last epoch): {final_map:.4f}\")\n",
    "        print(f\"Minimum mAP: {min_map:.4f}\")\n",
    "        print(f\"Maximum reduction: {results['baseline_map'] - min_map:.4f}\")\n",
    "        print(f\"Reduction percentage: {((results['baseline_map'] - min_map)/results['baseline_map'])*100:.1f}%\")\n",
    "\n",
    "        # Show per-epoch details\n",
    "        print(f\"\\nPer-epoch results:\")\n",
    "        for epoch in results['epochs'][-5:]:  # Show last 5 epochs\n",
    "            epoch_data = results['epoch_results'][epoch]\n",
    "            print(f\"Epoch {epoch}: mAP={epoch_data['map']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "835ab8be-9bf4-4ac7-83a0-e166dd79ec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated layer sizes: 32 -> 16 -> 8 -> 4 -> 2\n",
      "Figure saved as generated_patches_250.png\n"
     ]
    }
   ],
   "source": [
    "!python test_generator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3db684-d80b-4521-8ced-df4b162e142a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (psgan)",
   "language": "python",
   "name": "psgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
